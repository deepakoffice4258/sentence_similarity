{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f849b007",
   "metadata": {},
   "source": [
    "# Import Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "529bb3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from numpy.linalg import norm\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb7a2507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(s1,s2): \n",
    "    \"\"\"\n",
    "    This function takes vector forms of sentences and calculates cosine similarity [0-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    product = np.dot(s1,s2) # dot product between vectors of two sentences\n",
    "    norm_s1 = norm(s1) # calculate norm of A\n",
    "    norm_s2 = norm(s2) # calculate norm of B\n",
    "    return product/(norm_s1*norm_s2) # cosine similarity = Dot product/(Norm(A) * Norm(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cfec8",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ead9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e3d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the pretrained W2V model, trained on Google news data:\n",
    "\n",
    "w2v_model=KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c70864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence this function returns Average Word2Vec \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sent_vector = np.zeros(300) # since W2v gives 300 dimension representation for each word\n",
    "    for word in sentence.split(): # taking tokens from the sentence\n",
    "        vector = w2v_model[word] # getting w2v vector for the word\n",
    "        sent_vector += vector # adding this vector for performing Average W2v\n",
    "    sent_vector_final = sent_vector/len(sentence.split()) # performing the final mean operation\n",
    "    return sent_vector_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "713f4c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_score(sentence1,sentence2):\n",
    "    \"\"\"\n",
    "    This function takes two raw sentences, converts them into (W2V) vectors and returns the similarity score\n",
    "    \n",
    "    \"\"\"\n",
    "    s1 = get_w2v(sentence1)\n",
    "    s2 = get_w2v(sentence2)\n",
    "    \n",
    "    score = similarity(s1,s2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14e4c544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl is playing harp\n",
      "****************************************************************************************************\n",
      "girl is playing keyboard\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "s1 = \"girl is playing harp\"\n",
    "s2 =  \"girl is playing keyboard\"\n",
    "\n",
    "print(s1)\n",
    "print(\"*\"*100)\n",
    "print(s2)\n",
    "print(\"*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "929f3bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score through Average (W2V) : 0.8422383754578019\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity score through Average (W2V) :\",final_score(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6e38e5",
   "metadata": {},
   "source": [
    "# SentenceTransformer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d30b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2e25727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-nli-mean-tokens' # using the MEAN pooling strategy for CLS tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2e95324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482ecc27",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c93845cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = [\"Last night I was studying the whole night because of upcoming exam\",\n",
    "          \"Last night I was partying the whole night because of postponed exam\",\n",
    "          \"As exams are approaching I must study at long stretch at night\"]\n",
    "\n",
    "tut_vectors = model.encode(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f4c26ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 768)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tut_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21c098a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7606491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(tut_vectors[0],tut_vectors[1]) # similarity between sentence (1) and (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9cfd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69074416"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(tut_vectors[0],tut_vectors[2]) # similarity between sentence (1) and (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab617bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5401103"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(tut_vectors[1],tut_vectors[2]) # similarity between sentence (2) and (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db194fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 768)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_bert = [\"A girl is playing a harp\",\"A girl is playing a keyboard\"]\n",
    "bert_vectors = model.encode(lst_bert)\n",
    "bert_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8be2862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity score through (Sentence_Transformer) : 0.583888\n"
     ]
    }
   ],
   "source": [
    "print(\"Similarity score through (Sentence_Transformer) :\",similarity(bert_vectors[0],bert_vectors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80da8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(text_1,text_2):\n",
    "    \"\"\"\n",
    "    This function converts the input text to vectors of 768 dimensions and finds similarity between them.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    vector_1 = model.encode(text_1)\n",
    "    vector_2 = model.encode(text_2)\n",
    "    sim_score = similarity(vector_1,vector_2)\n",
    "    \n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba7a65a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A group of men play soccer on the beach.\n",
      "*****************************************************************************************************************************\n",
      "A group of boys are playing soccer on the beach.\n",
      "*****************************************************************************************************************************\n",
      "Similarity Score : 0.97384673\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"A group of men play soccer on the beach.\"\n",
    "text_2 = \"A group of boys are playing soccer on the beach.\"\n",
    "print(text_1)\n",
    "print(\"*\"*125)\n",
    "print(text_2)\n",
    "print(\"*\"*125)\n",
    "print(\"Similarity Score :\",sentence_similarity(text_1,text_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309cd14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
